"""YouTubeãƒˆãƒ¬ãƒ³ãƒ‰ï¼†ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ«."""

from datetime import datetime, timedelta

import pandas as pd
import streamlit as st

from src.analyzer import (
    fetch_and_analyze,
    filter_videos,
    sort_by_vs_ratio,
    videos_to_dataframe,
)
from src.suggest_api import (
    fetch_suggestions,
    fetch_suggestions_with_alphabet_soup,
    flatten_unique_suggestions,
)
from src.utils import format_number, video_url
from src.youtube_api import QuotaExceededError, get_quota_tracker

# â”€â”€â”€ ãƒšãƒ¼ã‚¸è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="YouTube ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ",
    page_icon="ğŸ”",
    layout="wide",
)

st.title("YouTube ãƒˆãƒ¬ãƒ³ãƒ‰ï¼†ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ«")

# â”€â”€â”€ APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    api_key = st.secrets["YOUTUBE_API_KEY"]
except (KeyError, FileNotFoundError):
    api_key = ""

if not api_key:
    st.error(
        "YouTube API ã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™ã€‚\n\n"
        "**ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ:**\n"
        "`.streamlit/secrets.toml` ã«ä»¥ä¸‹ã‚’è¿½åŠ :\n"
        '```\nYOUTUBE_API_KEY = "YOUR_API_KEY"\n```\n\n'
        "**Streamlit Community Cloud ã®å ´åˆ:**\n"
        "ã‚¢ãƒ—ãƒªè¨­å®š â†’ Secrets ã«ä¸Šè¨˜ã¨åŒã˜å†…å®¹ã‚’å…¥åŠ›\n\n"
        "**APIã‚­ãƒ¼å–å¾—æ‰‹é †:**\n"
        "1. [Google Cloud Console](https://console.cloud.google.com/) ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ\n"
        "2. YouTube Data API v3 ã‚’æœ‰åŠ¹åŒ–\n"
        "3. APIã‚­ãƒ¼ã‚’ä½œæˆ"
    )
    st.stop()

# â”€â”€â”€ ã‚µã‚¤ãƒ‰ãƒãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("æ¤œç´¢è¨­å®š")
    search_query = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", value="ä¸å‹•ç”£æŠ•è³‡", placeholder="ä¾‹: ä¸å‹•ç”£æŠ•è³‡")

    st.divider()
    st.subheader("ãƒ•ã‚£ãƒ«ã‚¿")

    max_subscribers = st.number_input(
        "ç™»éŒ²è€…æ•°ä¸Šé™",
        min_value=0,
        value=0,
        step=10000,
        help="0 = åˆ¶é™ãªã—",
    )

    min_views = st.number_input(
        "å†ç”Ÿæ•°ä¸‹é™",
        min_value=0,
        value=0,
        step=1000,
        help="0 = åˆ¶é™ãªã—",
    )

    min_vs_ratio = st.number_input(
        "V/Sæ¯”ç‡ä¸‹é™",
        min_value=0.0,
        value=0.0,
        step=0.1,
        format="%.1f",
        help="0.0 = åˆ¶é™ãªã—",
    )

    period_options = {
        "åˆ¶é™ãªã—": None,
        "éå»7æ—¥": 7,
        "éå»30æ—¥": 30,
        "éå»90æ—¥": 90,
        "éå»1å¹´": 365,
    }
    period_label = st.selectbox("æœŸé–“", options=list(period_options.keys()))
    period_days = period_options[period_label]

    st.divider()
    st.subheader("ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³")
    tracker = get_quota_tracker()
    st.metric("ä½¿ç”¨é‡", f"{tracker.used:,} / {tracker.daily_limit:,}")
    st.progress(min(tracker.usage_percent / 100, 1.0))
    st.caption(f"æ®‹ã‚Šç´„ {tracker.remaining:,} ãƒ¦ãƒ‹ãƒƒãƒˆ")

# â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã‚¿ãƒ–ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab_suggest, tab_buzz = st.tabs(["ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "ãƒã‚ºå‹•ç”»åˆ†æ"])

# â”€â”€â”€ ã‚¿ãƒ–1: ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_suggest:
    st.subheader("ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åé›†")
    st.caption("Googleã‚µã‚¸ã‚§ã‚¹ãƒˆéå…¬å¼APIã‚’ä½¿ã£ã¦ã€é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç¶²ç¾…çš„ã«å–å¾—ã—ã¾ã™ã€‚")

    col_base, col_soup = st.columns(2)

    with col_base:
        if st.button("åŸºæœ¬ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—", use_container_width=True):
            if not search_query:
                st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—ä¸­..."):
                    suggestions = fetch_suggestions(search_query)
                st.session_state["base_suggestions"] = suggestions

    with col_soup:
        if st.button("ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚¹ãƒ¼ãƒ—å–å¾—ï¼ˆç´„2åˆ†ï¼‰", use_container_width=True):
            if not search_query:
                st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                progress_bar = st.progress(0, text="ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ä¸­...")

                def update_progress(current: int, total: int):
                    progress_bar.progress(
                        current / total,
                        text=f"ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ä¸­... ({current}/{total})",
                    )

                soup_results = fetch_suggestions_with_alphabet_soup(
                    search_query,
                    delay=1.5,
                    progress_callback=update_progress,
                )
                progress_bar.empty()

                base = st.session_state.get("base_suggestions", [])
                if not base:
                    base = fetch_suggestions(search_query)
                    st.session_state["base_suggestions"] = base

                all_keywords = flatten_unique_suggestions(base, soup_results)
                st.session_state["all_suggestions"] = all_keywords

    # çµæœè¡¨ç¤º
    if "all_suggestions" in st.session_state and st.session_state["all_suggestions"]:
        keywords = st.session_state["all_suggestions"]
        st.success(f"{len(keywords)} ä»¶ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¾ã—ãŸ")

        df_kw = pd.DataFrame({"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": keywords})
        st.dataframe(df_kw, use_container_width=True, height=400)

        csv_kw = df_kw.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            csv_kw,
            file_name=f"suggestions_{search_query}.csv",
            mime="text/csv",
        )

    elif "base_suggestions" in st.session_state and st.session_state["base_suggestions"]:
        suggestions = st.session_state["base_suggestions"]
        st.info(f"{len(suggestions)} ä»¶ã®åŸºæœ¬ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")

        df_base = pd.DataFrame({"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": suggestions})
        st.dataframe(df_base, use_container_width=True)

# â”€â”€â”€ ã‚¿ãƒ–2: ãƒã‚ºå‹•ç”»åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_buzz:
    st.subheader("ãƒã‚ºå‹•ç”»åˆ†æï¼ˆV/Sæ¯”ç‡ï¼‰")
    st.caption("V/Sæ¯”ç‡ = å†ç”Ÿæ•° / ç™»éŒ²è€…æ•°ã€‚é«˜ã„ã»ã©ä¼ç”»åŠ›ã®ã‚ã‚‹å‹•ç”»ã§ã™ã€‚")

    if st.button("åˆ†æé–‹å§‹", type="primary", use_container_width=True):
        if not search_query:
            st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            published_after = None
            if period_days:
                dt = datetime.utcnow() - timedelta(days=period_days)
                published_after = dt.strftime("%Y-%m-%dT%H:%M:%SZ")

            try:
                with st.spinner("YouTube APIã‹ã‚‰å‹•ç”»ã‚’æ¤œç´¢ä¸­..."):
                    videos = fetch_and_analyze(
                        api_key, search_query, published_after=published_after
                    )

                # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
                filtered = filter_videos(
                    videos,
                    max_subscribers=max_subscribers if max_subscribers > 0 else None,
                    min_views=min_views if min_views > 0 else None,
                    min_vs_ratio=min_vs_ratio if min_vs_ratio > 0 else None,
                )

                # V/Sæ¯”ç‡ã§ã‚½ãƒ¼ãƒˆ
                sorted_videos = sort_by_vs_ratio(filtered)
                st.session_state["analyzed_videos"] = sorted_videos

            except QuotaExceededError:
                st.warning(
                    "APIã‚¯ã‚©ãƒ¼ã‚¿ã‚’è¶…éã—ã¾ã—ãŸã€‚"
                    "ã‚¯ã‚©ãƒ¼ã‚¿ã¯å¤ªå¹³æ´‹æ™‚é–“ã®åˆå‰0æ™‚ï¼ˆæ—¥æœ¬æ™‚é–“16:00ï¼‰ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ã€‚"
                )

    # çµæœè¡¨ç¤º
    if "analyzed_videos" in st.session_state and st.session_state["analyzed_videos"]:
        sorted_videos = st.session_state["analyzed_videos"]
        st.success(f"{len(sorted_videos)} ä»¶ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

        # ã‚µãƒ ãƒã‚¤ãƒ«ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º
        cols_per_row = 3
        for i in range(0, len(sorted_videos), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                idx = i + j
                if idx >= len(sorted_videos):
                    break
                v = sorted_videos[idx]
                with col:
                    with st.container(border=True):
                        st.image(v.thumbnail_url, use_container_width=True)
                        st.markdown(
                            f"**[{v.title}]({video_url(v.video_id)})**"
                        )
                        metric_cols = st.columns(3)
                        metric_cols[0].metric("V/Sæ¯”ç‡", f"{v.vs_ratio:.1f}")
                        metric_cols[1].metric("å†ç”Ÿæ•°", format_number(v.view_count))
                        metric_cols[2].metric("ç™»éŒ²è€…", format_number(v.subscriber_count))

        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼†CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.divider()
        df = videos_to_dataframe(sorted_videos)
        st.dataframe(df, use_container_width=True, height=400)

        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            csv,
            file_name=f"buzz_videos_{search_query}.csv",
            mime="text/csv",
        )

    elif "analyzed_videos" in st.session_state:
        st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ç·©ã‚ã¦ãŠè©¦ã—ãã ã•ã„ã€‚")
